
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Let's catch UFO"]},{"cell_type":"markdown","metadata":{},"source":["1. Key things to include: Project Overview #Stakeholder & Business QUESTIONS #Data Soucres #Links to notebooks, preentations, and dashboards\n","\n","2. Additional Notes Business Problem: A clear statement of the business problem you are solving.\n","\n","3. Dataset Information: A description of your dataset(s) and how you plan to use it.\n","\n","4. Methods: Brief explanation of your analysis steps.\n","\n","5. Results and Recommendations: What insights and recommendations are you providing to the stakeholder?\n","\n","6. Links: Include links to the Jupyter notebook, dashboard, and presentation files.\n","\n","Remember no code just visuals non techical\n","\n","Example Template:\n","\n","Project Title\n","\n","Overview A concise summary of the project, including the purpose, the problem it addresses, and the key findings.\n","Goal of the project: Clearly state the objective. Context: Brief background or motivation for the project. Main results/insights: Summarize key outcomes or insights from your analysis.\n","\n","Repository Structure (Probably should go at the bottom Provide an outline of the repository, explaining what each folder and file contains. ðŸ“ /data # Contains raw and cleaned datasets ðŸ“ /notebooks # Jupyter Notebooks or code scripts used in analysis ðŸ“ /scripts # Python or other scripts for data cleaning and modeling ðŸ“ /images # Graphs, figures, Tableau dashboard files ðŸ“„ README.md # Documentation of the project ðŸ“„ requirements.txt # Packages and dependencies needed to run the code ðŸ“„ presentation.pdf # Final presentation slides\n","/data: A brief description of the datasets used, including sources. /notebooks: Notebooks detailing data exploration, cleaning, analysis, and modeling. /scripts: Python scripts for automating tasks like data processing. /images: Contains final visuals, plots, or links to Tableau dashboards.\n","\n","Data Science Steps Outline the key steps taken during the project:\n","Data Collection: How data was sourced (e.g., APIs, web scraping, public datasets). Data Cleaning: Techniques used for cleaning and preprocessing data (e.g., handling missing values). Exploratory Data Analysis (EDA): Summary of insights found during the EDA phase. Modeling: Brief overview of the models used and their performance. Results: Main findings from the analysis or predictive models.\n","\n","Instructions for Use Guide users on how to navigate the repository, including how to replicate the project on their local machine: (git clone link)\n","\n","Tableau Dashboard Include a link to the Tableau dashboard:\n","\n","Tableau Dashboard\n","6. Presentation Provide a link to the final project presentation:\n","\n","Sources\n","List any references or external data sources used: Data Source 1(Kaggle)\n","\n","Commit History Provide an overview of the commit history to demonstrate project development and collaboration. Link to the repositoryâ€™s commit history for detailed tracking:\n","View commit history\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["1. Stakeholder Questions:\n","- What regions and times have the highest frequency of UFO sightings?\n","- Are there notable patterns in UFO shapes, descriptions, or lengths of encounters?\n","- Can any correlations be drawn between the timing (season, time of day) and the likelihood of a sighting?\n","((- Is there a potential for identifying anomalies or \"false positives\" in the sighting reports?))\n","2. Business Problem: Provide clear and engaging data visualizations that help stakeholders (researchers, enthusiasts, or possibly governmental entities) understand trends in UFO sightings, aiding decision-making for further research or public communication."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#Import\n","import numpy as np \n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Users/jeesoojhun/Documents/Flatiron/Phase-1-Project/data/ufo_data/ufo-sightings-transformed.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/jeesoojhun/Documents/Flatiron/Phase-1-Project/data/ufo_data/ufo-sightings-transformed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n","File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/anaconda3/envs/cohort_env/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jeesoojhun/Documents/Flatiron/Phase-1-Project/data/ufo_data/ufo-sightings-transformed.csv'"]}],"source":["df = pd.read_csv('/Users/jeesoojhun/Documents/Flatiron/Phase-1-Project/data/ufo_data/ufo-sightings-transformed.csv', index_col='Unnamed: 0')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["# Data Cleaning"]},{"cell_type":"markdown","metadata":{},"source":["**Time Standardization**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardize Dates and Times\n","#Convert Date_time to datetime format\n","df['Date_time'] = pd.to_datetime(df['Date_time'], errors='coerce')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardize the date_documented column\n","df['date_documented'] = pd.to_datetime(df['date_documented'], errors='coerce')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardize Year, Month, Hour and Season Column \n","#Year, Month, and Hour : are they derived accurately from Date_time?\n","#Season: grouping months into seasons\n","df['Year'] = df['Date_time'].dt.year\n","df['Month'] = df['Date_time'].dt.month\n","df['Hour'] = df['Date_time'].dt.hour\n","\n","#Seasons\n","df['Season'] = df['Month'].apply(lambda x: 'Winter' if x in [12, 1, 2] else 'Spring' if x in [3, 4, 5] else 'Summer' if x in [6, 7, 8] else 'Autumn')\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardize the length of encounter seconds column\n","# Convert 'length_of_encounter_seconds' to numeric, forcing errors to NaN\n","df['length_of_encounter_seconds'] = pd.to_numeric(df['length_of_encounter_seconds'], errors='coerce')\n","\n","# Remove outliers (e.g., encounters longer than a day)\n","df = df[df['length_of_encounter_seconds'] <= 86400]  # 86400 seconds = 24 hours\n","\n","# Verify changes\n","df['length_of_encounter_seconds'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Display unique values to understand various formats in 'Encounter_Duration'\n","df['Encounter_Duration'].unique()[:20]  # Display first 20 unique values to analyze different formats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Unify the units into seconds and convert to numeric in Encounter_Duration column"]},{"cell_type":"markdown","metadata":{},"source":["**Handling Geographical Data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardize Country Codes and Names.\n","#Ensure that the country codes and Country values are consistent.\n","df['Country_Code']=df['Country_Code'].str.upper().str.strip()\n","df['Country'] = df['Country'].str.title().str.strip()\n","\n","df['Country_Code'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ensure latitude and longitude are within valid ranges\n","df = df[(df['latitude'] >= -90) & (df['latitude'] <= 90)]\n","df = df[(df['longitude'] >= -180) & (df['longitude'] <= 180)]\n","\n","# Verify the changes\n","df[['latitude', 'longitude']].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Replace country values with longitudes and latitudes using geopanda or geopy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#pip install geopy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Decide to just drop the rows with missing values in the Country column\n","# Drop rows with missing values in 'Country_Code', 'Country', 'Region', 'Locale', and 'UFO_shape'\n","df.dropna(subset=['Country_Code', 'Country', 'Region', 'Locale'], inplace=True)\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Verify changes to ensure rows with missing values in the specified columns are dropped\n","print(df[['Country_Code', 'Country', 'Region', 'Locale', 'UFO_shape']].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['UFO_shape'].fillna('Unknown', inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Questions"]}],"metadata":{"kernelspec":{"display_name":"cohort_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":2}
